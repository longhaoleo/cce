{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26d68cc3",
   "metadata": {},
   "source": [
    "# Stable Diffusion xl 跨注意力可视化（组合概念纠缠）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f43011",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from diffusers.models.attention_processor import AttnProcessor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dtype = torch.float16  # v1-5 支持 fp16 推理\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d96509",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class CrossAttnStore(AttnProcessor):\n",
    "    \"\"\"\n",
    "    拦截 cross-attention，存储 softmax(QK^T) 后的注意力。\n",
    "    仅对 cross-attn (attn.is_cross_attention=True) 生效。\n",
    "    \"\"\"\n",
    "    def __init__(self, attn_store: Dict):\n",
    "        super().__init__()\n",
    "        self.store = attn_store  # {\"maps\": [(B,H,N,L), ...], \"meta\": [...]}\n",
    "\n",
    "    def __call__(self, attn, hidden_states, encoder_hidden_states=None, attention_mask=None, temb=None):\n",
    "        # 复制自 diffusers 默认 AttnProcessor，但在 softmax 后记录\n",
    "        batch_size, sequence_length, _ = hidden_states.shape\n",
    "        attn = attn.to_qkv(dtype=hidden_states.dtype)\n",
    "        query = attn.to_q(hidden_states)\n",
    "        key = attn.to_k(encoder_hidden_states if encoder_hidden_states is not None else hidden_states)\n",
    "        value = attn.to_v(encoder_hidden_states if encoder_hidden_states is not None else hidden_states)\n",
    "\n",
    "        inner_dim = key.shape[-1]\n",
    "        head_dim = inner_dim // attn.heads\n",
    "        query = query.view(batch_size, -1, attn.heads, head_dim).transpose(1, 2)\n",
    "        key = key.view(batch_size, -1, attn.heads, head_dim).transpose(1, 2)\n",
    "        value = value.view(batch_size, -1, attn.heads, head_dim).transpose(1, 2)\n",
    "\n",
    "        # scaled dot-product attention\n",
    "        scale = attn.scale\n",
    "        attn_scores = torch.matmul(query, key.transpose(-1, -2)) * scale\n",
    "\n",
    "        if attention_mask is not None:\n",
    "            attn_scores = attn_scores + attention_mask\n",
    "\n",
    "        attn_probs = attn_scores.softmax(dim=-1)  # (B, heads, query_len, key_len)\n",
    "\n",
    "        # ---- 存储 cross-attn 的 softmax 后权重 ----\n",
    "        if attn.is_cross_attention:\n",
    "            self.store[\"maps\"].append(attn_probs.detach().cpu())\n",
    "\n",
    "        hidden_states = torch.matmul(attn_probs, value)\n",
    "        hidden_states = hidden_states.transpose(1, 2).reshape(batch_size, -1, inner_dim)\n",
    "        hidden_states = attn.to_out[0](hidden_states)\n",
    "        hidden_states = attn.to_out[1](hidden_states)\n",
    "        return hidden_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb58403",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def register_attn_store(pipe, store: Dict):\n",
    "    proc = CrossAttnStore(store)\n",
    "    for name, module in pipe.unet.named_modules():\n",
    "        if \"attn2\" in name:  # cross-attn 层通常叫 attn2\n",
    "            module.set_processor(proc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0904a2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def find_token_indices(tokenizer, prompt: str, target: str) -> List[int]:\n",
    "    \"\"\"\n",
    "    在 tokenized prompt 中找到与 target(小写) 匹配的 token 索引。\n",
    "    简单做法：逐 token 解码匹配子串。\n",
    "    \"\"\"\n",
    "    ids = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"][0]\n",
    "    tokens = [tokenizer.decode([i]).strip().lower() for i in ids]\n",
    "    target = target.lower()\n",
    "    return [i for i, t in enumerate(tokens) if target in t and t != \"\"]\n",
    "\n",
    "def aggregate_maps(attn_maps: List[torch.Tensor]) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    attn_maps: list of (B, H, N, L) over all cross-attn layers/steps\n",
    "    返回 shape (L, sqrt(N), sqrt(N)) 的平均注意力（对 batch/head/层 求均值）。\n",
    "    \"\"\"\n",
    "    if len(attn_maps) == 0:\n",
    "        raise ValueError(\"没有捕获到 cross-attention map\")\n",
    "    # concat -> (S, B, H, N, L)\n",
    "    stacked = torch.stack(attn_maps)  # S: layers*steps\n",
    "    # mean over S, H, B\n",
    "    mean_map = stacked.mean(dim=(0,1,2))  # (N, L)\n",
    "    return mean_map  # query_len x key_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bb75d5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_token_map(mean_map: torch.Tensor, token_indices: List[int], hw: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    mean_map: (N, L)\n",
    "    token_indices: 需要的 key token index 列表\n",
    "    hw: 空间边长 sqrt(N)\n",
    "    \"\"\"\n",
    "    if len(token_indices) == 0:\n",
    "        raise ValueError(\"未找到目标 token\")\n",
    "    # 对目标 tokens 取均值\n",
    "    sub = mean_map[:, token_indices].mean(dim=-1)  # (N,)\n",
    "    attn_hw = sub.reshape(int(hw), int(hw))  # (h, w)\n",
    "    return attn_hw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f36612",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def upscale_to_512(attn_hw: torch.Tensor) -> np.ndarray:\n",
    "    attn = attn_hw.unsqueeze(0).unsqueeze(0)  # (1,1,h,w)\n",
    "    up = F.interpolate(attn, size=(512,512), mode=\"bilinear\", align_corners=False)\n",
    "    up = up[0,0].cpu().numpy()\n",
    "    up = (up - up.min()) / (up.max() - up.min() + 1e-8)\n",
    "    return up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e6ee65",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def overlay_heatmap(rgb: np.ndarray, heat: np.ndarray, alpha=0.5, cmap=cv2.COLORMAP_JET):\n",
    "    heat_color = cv2.applyColorMap((heat*255).astype(np.uint8), cmap)\n",
    "    heat_color = cv2.cvtColor(heat_color, cv2.COLOR_BGR2RGB)\n",
    "    over = (alpha*heat_color + (1-alpha)*rgb).astype(np.uint8)\n",
    "    return over\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def iou_soft(a: np.ndarray, b: np.ndarray):\n",
    "    num = np.minimum(a, b).sum()\n",
    "    den = np.maximum(a, b).sum() + 1e-8\n",
    "    return num / den\n",
    "\n",
    "def cosine_sim(a: np.ndarray, b: np.ndarray):\n",
    "    a_flat, b_flat = a.flatten(), b.flatten()\n",
    "    return np.dot(a_flat, b_flat) / (np.linalg.norm(a_flat)*np.linalg.norm(b_flat)+1e-8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec354650",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_attention(prompt: str, subject: str, action: str, guidance_scale=7.5, steps=30):\n",
    "    store = {\"maps\": []}\n",
    "\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(\n",
    "        \"runwayml/stable-diffusion-v1-5\",\n",
    "        torch_dtype=dtype,\n",
    "        safety_checker=None,\n",
    "    ).to(device)\n",
    "\n",
    "    register_attn_store(pipe, store)\n",
    "\n",
    "    # 生成\n",
    "    with torch.autocast(device):\n",
    "        image = pipe(prompt, guidance_scale=guidance_scale, num_inference_steps=steps).images[0]\n",
    "    rgb = np.array(image)\n",
    "\n",
    "    # 聚合注意力\n",
    "    mean_map = aggregate_maps(store[\"maps\"])  # (N, L)\n",
    "    hw = int(np.sqrt(mean_map.shape[0]))  # e.g., 16x16 or 32x32\n",
    "\n",
    "    tokenizer = pipe.tokenizer\n",
    "    subj_idx = find_token_indices(tokenizer, prompt, subject)\n",
    "    act_idx  = find_token_indices(tokenizer, prompt, action)\n",
    "\n",
    "    subj_map = upscale_to_512(get_token_map(mean_map, subj_idx, hw))\n",
    "    act_map  = upscale_to_512(get_token_map(mean_map, act_idx, hw))\n",
    "\n",
    "    subj_overlay = overlay_heatmap(rgb, subj_map, alpha=0.45)\n",
    "    act_overlay  = overlay_heatmap(rgb, act_map,  alpha=0.45)\n",
    "\n",
    "    # 量化纠缠\n",
    "    iou = iou_soft(subj_map, act_map)\n",
    "    cos = cosine_sim(subj_map, act_map)\n",
    "\n",
    "    # 可视化\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18,6))\n",
    "    axes[0].imshow(rgb); axes[0].set_title(\"生成图像\"); axes[0].axis(\"off\")\n",
    "    axes[1].imshow(subj_overlay); axes[1].set_title(f\"{subject} 注意力叠加\"); axes[1].axis(\"off\")\n",
    "    axes[2].imshow(act_overlay);  axes[2].set_title(f\"{action} 注意力叠加\"); axes[2].axis(\"off\")\n",
    "    plt.suptitle(f\"IoU={iou:.3f} | Cosine={cos:.3f}\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return {\"image\": image, \"subj_map\": subj_map, \"act_map\": act_map, \"iou\": iou, \"cos\": cos}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c66d95a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "result = visualize_attention(\n",
    "    prompt=\"A photo of Mickey Mouse smoking\",\n",
    "    subject=\"mickey\",\n",
    "    action=\"smoking\",\n",
    "    guidance_scale=7.5,\n",
    "    steps=30,\n",
    ")\n",
    "print(f\"IoU={result['iou']:.4f}, Cosine={result['cos']:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
